{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as pt \n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5572"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data from spam.csv\n",
    "\n",
    "dataset = pd.read_csv('spam.csv' , usecols=[0,1], encoding ='ISO-8859-1')\n",
    "dataset.head()\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...'\n",
      " 'Ok lar... Joking wif u oni...'\n",
      " \"Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\"\n",
      " 'U dun say so early hor... U c already then say...'\n",
      " \"Nah I don't think he goes to usf, he lives around here though\"\n",
      " \"FreeMsg Hey there darling it's been 3 week's now and no word back! I'd like some fun you up for it still? Tb ok! XxX std chgs to send, å£1.50 to rcv\"\n",
      " 'Even my brother is not like to speak with me. They treat me like aids patent.'\n",
      " \"As per your request 'Melle Melle (Oru Minnaminunginte Nurungu Vettam)' has been set as your callertune for all Callers. Press *9 to copy your friends Callertune\"\n",
      " 'WINNER!! As a valued network customer you have been selected to receivea å£900 prize reward! To claim call 09061701461. Claim code KL341. Valid 12 hours only.'\n",
      " 'Had your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free! Call The Mobile Update Co FREE on 08002986030']\n",
      "[0 0 1 0 0 1 0 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Removes the extra whitespace\n",
    "dataset['labels'] = dataset['labels'].str.strip()\n",
    "\n",
    "# Map the labels to binary values\n",
    "dataset['labels'] = dataset['labels'].map({'not spam': 0, 'spam': 1})\n",
    "\n",
    "# Convert to NumPy arrays\n",
    "sentences = dataset['data'].values\n",
    "labels = dataset['labels'].values\n",
    "\n",
    "print(sentences[:10])\n",
    "print(labels[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Sentences: ['Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...'\n",
      " 'Ok lar... Joking wif u oni...'\n",
      " \"Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\"\n",
      " 'U dun say so early hor... U c already then say...'\n",
      " \"Nah I don't think he goes to usf, he lives around here though\"]\n",
      "Training Labels: [0 0 1 0 0]\n",
      "Testing Sentences: ['That depends. How would you like to be treated? :)'\n",
      " 'Right on brah, see you later'\n",
      " 'Waiting in e car 4 my mum lor. U leh? Reach home already?'\n",
      " 'Your 2004 account for 07XXXXXXXXX shows 786 unredeemed points. To claim call 08719181259 Identifier code: XXXXX Expires 26.03.05'\n",
      " 'Do you want a new video handset? 750 anytime any network mins? Half Price Line Rental? Camcorder? Reply or call 08000930705 for delivery tomorrow']\n",
      "Testing Labels: [0 0 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "\n",
    "training_size = int(0.7*len(sentences))\n",
    "\n",
    "training_sentences = sentences[:training_size]\n",
    "testing_sentences = sentences[training_size:]\n",
    "training_labels = labels[:training_size]\n",
    "testing_labels = labels[training_size:]\n",
    "\n",
    "print(\"Training Sentences:\" , training_sentences[:5])\n",
    "print(\"Training Labels:\", training_labels[:5])\n",
    "print(\"Testing Sentences:\" , testing_sentences[:5])\n",
    "print(\"Testing Labels:\" ,  testing_labels[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words: 7439\n"
     ]
    }
   ],
   "source": [
    "# Tokenized the training\n",
    "\n",
    "tokenizer = Tokenizer(num_words = 10000)\n",
    "tokenizer.fit_on_texts(training_sentences)\n",
    "#print(tokenizer.word_index)\n",
    "print(\"Number of unique words:\", len(tokenizer.word_index))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Sequences: [[54, 426, 3510, 711, 786, 640, 65, 8, 1138, 85, 121, 309, 1297, 131, 2360, 1024, 66, 59, 3511, 136], [46, 331, 2361, 562, 6, 1817], [50, 427, 8, 22, 4, 859, 934, 2, 170, 1513, 1025, 534, 1514, 1818, 253, 1819, 71, 1513, 2, 1820, 2, 347, 427, 490, 935, 72, 443, 185, 602, 388, 2362], [6, 254, 152, 25, 320, 3512, 6, 142, 148, 55, 152], [860, 1, 92, 99, 69, 428, 2, 1139, 69, 1821, 203, 102, 491]]\n",
      "Testing Sequences: [[19, 1225, 52, 172, 3, 58, 2, 29, 6154], [145, 18, 7353, 96, 3, 120], [244, 8, 131, 300, 44, 11, 775, 86, 6, 528, 371, 83, 148], [13, 1546, 356, 12, 3061, 383, 2420, 2421, 809, 2, 123, 17, 1046, 492, 6671, 1047, 732, 3145], [30, 3, 73, 4, 100, 440, 2492, 825, 826, 101, 444, 373, 350, 573, 305, 1213, 942, 88, 27, 17, 943, 12, 567, 150]]\n"
     ]
    }
   ],
   "source": [
    "# Create sequences of tokens which represents each sentence\n",
    "\n",
    "train_sequences = tokenizer.texts_to_sequences(training_sentences)\n",
    "test_sequences = tokenizer.texts_to_sequences(testing_sentences)\n",
    "\n",
    "print(\"Training Sequences:\" , train_sequences[:5])\n",
    "print(\"Testing Sequences:\" , test_sequences[:5])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of training sequences: 3900\n",
      "Length of training sequence: 189\n",
      "Shape of padded test sequences: (1672, 189)\n",
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0   54  426 3510  711  786  640   65    8 1138   85  121  309 1297\n",
      "  131 2360 1024   66   59 3511  136]\n"
     ]
    }
   ],
   "source": [
    "# Pad the sequences to have the same length\n",
    "\n",
    "padded_train = pad_sequences(train_sequences)\n",
    "\n",
    "no_of_sequences = padded_train.shape[0]\n",
    "length_of_sequence = padded_train.shape[1]\n",
    "\n",
    "padded_test = pad_sequences(test_sequences, maxlen = length_of_sequence)\n",
    "\n",
    "print(\"No. of training sequences:\", no_of_sequences)\n",
    "print(\"Length of training sequence:\", length_of_sequence)\n",
    "print(\"Shape of padded test sequences:\",  padded_test.shape)\n",
    "print(padded_train[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
